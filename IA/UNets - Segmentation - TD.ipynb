{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13b5d2db",
   "metadata": {},
   "source": [
    "# UNets and segmentation.\n",
    " \n",
    "## The question we want to answer experimentally is: To what extent the architecture of UNet is responsible for the success of segmentation?\n",
    "\n",
    "\n",
    "## Please check out the founding paper: https://arxiv.org/abs/1505.04597\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "706b9b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/IPython/core/magics/pylab.py:159: UserWarning: pylab import has clobbered these variables: ['plt']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  warn(\"pylab import has clobbered these variables: %s\"  % clobbered +\n"
     ]
    }
   ],
   "source": [
    "### standard imports\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import matplotlib as plt\n",
    "import torch.optim as optim\n",
    "import os\n",
    "### line below is for mac in particular. Remove if not needed\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5deb34a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "transform_train = transforms.Compose([\n",
    "        transforms.ToTensor(),transforms.Resize((128, 128), interpolation=transforms.InterpolationMode.NEAREST)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23887230",
   "metadata": {},
   "source": [
    "## We use a dataset that is accessible within pytorch: the OxfordIIIPet dataset with segmentation of animals. \n",
    "## In the code above, we defined \"transform_train\" which is a simple resize operation since the images do not have the same size.\n",
    "## It is also possible to use a class of transformation of the training set in order to augment the dataset, or to make it more invariant to some natural transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ad32e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "### first introduce some parameters.\n",
    "batch_size = 32 # you can modify.\n",
    "test_batch_size = 32 # you can modify\n",
    "data_augmentation = False # used to augment data with a set of transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff0ff18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OxfordData(Dataset):\n",
    "    def __init__(self,split = \"trainval\",option = True):\n",
    "        self.data = datasets.OxfordIIITPet(root='.data/OxfordIIITPet', split=split, target_types=\"segmentation\", download=True,\n",
    "                               transform=transform_train)\n",
    "        self.option = option\n",
    "        print(len(self.data),\" longueur des données\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        x,y = self.data[item]\n",
    "        if data_augmentation == True:\n",
    "            random_transform_1 = transforms.RandomCrop(80)\n",
    "            #random_transform_2 = transforms.RandomAffine((-180, 179), scale=(0.8, 1.2))\n",
    "            transform = transforms.Compose([transforms.ToTensor(),transforms.RandomApply(torch.nn.ModuleList([random_transform_1])), transforms.Resize((128, 128), interpolation=transforms.InterpolationMode.NEAREST)])\n",
    "            transform2 = transforms.Compose([transforms.RandomApply(torch.nn.ModuleList([random_transform_1])), transforms.Resize((128, 128), interpolation=transforms.InterpolationMode.NEAREST)])\n",
    "            x = transform2(x)\n",
    "        else:\n",
    "            transform = transforms.Compose([transforms.ToTensor(), transforms.Resize((128, 128), interpolation=transforms.InterpolationMode.NEAREST)])\n",
    "        z = transform(y)\n",
    "        z = z / torch.max(z)\n",
    "        return torch.cat((x,z),dim=0)\n",
    "\n",
    "\n",
    "def get_OxfordPet_loaders(batch_size= batch_size, test_batch_size=test_batch_size, perc=1.0):\n",
    "    train_loader = DataLoader(\n",
    "        OxfordData(\"trainval\"), batch_size=batch_size,\n",
    "        shuffle=True, num_workers=0, drop_last=True\n",
    "    )\n",
    "\n",
    "    train_eval_loader = DataLoader(\n",
    "        OxfordData(\"trainval\"),\n",
    "        batch_size=test_batch_size, shuffle=False, num_workers=0, drop_last=True\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        OxfordData(split = \"test\",option=False),\n",
    "        batch_size=test_batch_size, shuffle=False, num_workers=0, drop_last=True\n",
    "    )\n",
    "    return train_loader, test_loader, train_eval_loader\n",
    "\n",
    "def inf_generator(iterable):\n",
    "    \"\"\"Allows training with DataLoaders in a single infinite loop:\n",
    "        for i, (x, y) in enumerate(inf_generator(train_loader)):\n",
    "    \"\"\"\n",
    "    iterator = iterable.__iter__()\n",
    "    while True:\n",
    "        try:\n",
    "            yield iterator.__next__()\n",
    "        except StopIteration:\n",
    "            iterator = iterable.__iter__()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d3ba9a",
   "metadata": {},
   "source": [
    "## Data are four channels images. The first three ones contain the image and the last one the segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa1fb34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://thor.robots.ox.ac.uk/datasets/pets/images.tar.gz to .data/OxfordIIITPet/oxford-iiit-pet/images.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 791918971/791918971 [00:11<00:00, 66539989.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed download. Trying https -> http instead. Downloading http://thor.robots.ox.ac.uk/datasets/pets/images.tar.gz to .data/OxfordIIITPet/oxford-iiit-pet/images.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 524288/791918971 [00:00<01:49, 7251686.78it/s]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 122] Disk quota exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Downloading \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" to \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0m_urlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mURLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36m_urlretrieve\u001b[0;34m(url, filename, chunk_size)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUSER_AGENT\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0m_save_response_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36m_save_response_content\u001b[0;34m(content, destination, length)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 122] Disk quota exceeded",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-89cd0c291523>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### On affiche le type de données.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m train_loader, test_loader, train_eval_loader = get_OxfordPet_loaders(\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     )\n",
      "\u001b[0;32m<ipython-input-6-f49020a25a03>\u001b[0m in \u001b[0;36mget_OxfordPet_loaders\u001b[0;34m(batch_size, test_batch_size, perc)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_OxfordPet_loaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     train_loader = DataLoader(\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mOxfordData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trainval\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     )\n",
      "\u001b[0;32m<ipython-input-6-f49020a25a03>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, split, option)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mOxfordData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"trainval\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moption\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         self.data = datasets.OxfordIIITPet(root='.data/OxfordIIITPet', split=split, target_types=\"segmentation\", download=True,\n\u001b[0m\u001b[1;32m      4\u001b[0m                                transform=transform_train)\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moption\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/oxford_iiit_pet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, split, target_types, transforms, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/oxford_iiit_pet.py\u001b[0m in \u001b[0;36m_download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RESOURCES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mdownload_and_extract_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m     \u001b[0mdownload_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0marchive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"http:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failed download. Trying https -> http instead. Downloading \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" to \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                 \u001b[0m_urlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36m_urlretrieve\u001b[0;34m(url, filename, chunk_size)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_urlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1024\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUSER_AGENT\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0m_save_response_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36m_save_response_content\u001b[0;34m(content, destination, length)\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 122] Disk quota exceeded"
     ]
    }
   ],
   "source": [
    "### On affiche le type de données.\n",
    "\n",
    "train_loader, test_loader, train_eval_loader = get_OxfordPet_loaders(\n",
    "        batch_size, test_batch_size\n",
    "    )\n",
    "\n",
    "data_gen = inf_generator(train_loader)\n",
    "batches_per_epoch = len(train_loader)\n",
    "test_gen = inf_generator(test_loader)\n",
    "for i in range(2):\n",
    "    x = data_gen.__next__()\n",
    "    \n",
    "\n",
    "figure = plt.figure(figsize=(12, 12))\n",
    "cols,rows = 4,1\n",
    "for i in range(0, cols * rows):\n",
    "    z = x.numpy()\n",
    "    label = x[:, -1, :, :].unsqueeze(1)\n",
    "    index = i\n",
    "    figure.add_subplot(rows, cols, i+1)\n",
    "    plt.imshow(z[i, 0, :, :])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figure = plt.figure(figsize=(12, 12))\n",
    "cols,rows = 4,1\n",
    "for i in range(0, cols * rows):\n",
    "    figure.add_subplot(rows, cols, i+1)\n",
    "    plt.imshow(label[i, 0, :, :])\n",
    "    \n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a5a28b",
   "metadata": {},
   "source": [
    "## Question 1: Implement a UNet class:\n",
    "### 1. Below are two elementary functions: one which is downsampling after convolutions, nonlinearities and maxpooling. Batchnorm is also used.\n",
    "### 2. Using these two functions, construct a simple UNet:\n",
    "### The downsampling path is relatively straightforward, it is simply given by the composition of contract_blocks.\n",
    "### In the upsampling path, you need to concatenate the results obtained at each level in the downsampling path with the result in the corresponding expand_block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb0a3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contract_block(self, in_channels, out_channels, kernel_size, padding):\n",
    "    contract = nn.Sequential(\n",
    "        torch.nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n",
    "        torch.nn.BatchNorm2d(out_channels),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n",
    "        torch.nn.BatchNorm2d(out_channels),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.MaxPool2d(kernel_size=kernel_size, stride=2, padding=1)\n",
    "    )\n",
    "    return contract\n",
    "\n",
    "\n",
    "def expand_block(self, in_channels, out_channels, kernel_size, padding, output_padding=1):\n",
    "    expand = nn.Sequential(torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=padding),\n",
    "                           torch.nn.BatchNorm2d(out_channels),\n",
    "                           torch.nn.ReLU(),\n",
    "                           torch.nn.Conv2d(out_channels, out_channels, kernel_size, stride=1, padding=padding),\n",
    "                           torch.nn.BatchNorm2d(out_channels),\n",
    "                           torch.nn.ReLU(),\n",
    "                           torch.nn.ConvTranspose2d(out_channels, out_channels, kernel_size=kernel_size, stride=2,\n",
    "                                                    padding=1, output_padding=output_padding)\n",
    "                           )\n",
    "    return expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fa34a7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "### your code here.\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "\n",
    "    def __call__(self, x):\n",
    "        # downsampling part\n",
    "        result = 0\n",
    "        # upsampling part       \n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af73dde7",
   "metadata": {},
   "source": [
    "## Question 2: Adapt the code below to implement a simple convolution model, possibly with skip connections as a ResNet like architecture with elementary blocks which are convolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1b9aa0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNET(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,resnet = False):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.depth = 4\n",
    "        self.resnet = resnet\n",
    "        kernel_size = 3\n",
    "        for i in range(self.depth):\n",
    "            self.layers.append(self.block(in_channels,out_channels,kernel_size))\n",
    "        \n",
    "\n",
    "    def __call__(self, x):\n",
    "        # downsampling part\n",
    "        y = self.layers[0](x)\n",
    "        for i in range(1,(self.depth)-1):\n",
    "            if self.resnet == True:\n",
    "                y = y + self.layers[i](y)\n",
    "            else: \n",
    "                y = self.layers[i](y)\n",
    "        return self.layers[-1](y)\n",
    "        \n",
    "\n",
    "    def block(self, in_channels, out_channels, kernel_size, padding = 1):\n",
    "        bloc = nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n",
    "            torch.nn.BatchNorm2d(out_channels),\n",
    "            torch.nn.ReLU())\n",
    "        return bloc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241a105f",
   "metadata": {},
   "source": [
    "### We set up an optimizer (from published experiences, Adam seems the best default optimizer) and a scheduler to decrease the learning rate at every epoch.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cfcae88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### In order to evaluate the results, you can use the following functions:\n",
    "def dice(a,b):\n",
    "    return - 2 * (torch.sum(a * b) +0.01)/(torch.sum(a) + torch.sum(b) - torch.sum(a * b) + 0.01)\n",
    "def dice_on_batch(a,b):\n",
    "    bs = a.shape[0]\n",
    "    loss = 0\n",
    "    for i in range(bs):\n",
    "        loss+= dice(a[i,:,:,:], b[i,:,:,:])\n",
    "    return loss\n",
    "\n",
    "def ssd(a,b):\n",
    "    return torch.sum((a - b)**2)\n",
    "\n",
    "def performance(loader,n_iterations=20,genre = \"training\"):\n",
    "    performance = 0\n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_iterations):\n",
    "            x = loader.__next__()\n",
    "            label = x[:, -1, :, :]\n",
    "            x = x[:, :3, :, :]\n",
    "            x = x.to(device)\n",
    "            label = label.unsqueeze(1)\n",
    "            label = label.to(device)\n",
    "            h = model(x)\n",
    "            loss = ssd(h, label)\n",
    "            performance += loss\n",
    "        result = performance/n_iterations\n",
    "    print(\"performance in \"+genre+\" is on a batch of \"+str(n_iterations) +\" : \", result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "210c5db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the learning rate:\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9822db04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNET(3,3,resnet = True)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr, betas=(0.95, 0.95))\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163f5699",
   "metadata": {},
   "source": [
    "## Question 3: Implement the learning loop and test it on a UNet or CNet and show the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "186a181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### your code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a286baff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
